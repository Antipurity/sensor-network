The sensor network can represent any interaction of two things.

[Isn't having yet another universal standard bad, though?](https://xkcd.com/927/)

[Lots ](https://stackoverflow.com/questions/7284/what-is-turing-complete)[of ](https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414)[things ](https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life)[are ](https://en.wikipedia.org/wiki/Evolution)[theo](https://deepmind.com/research/publications/2021/Reward-is-Enough)[ret](https://arxiv.org/abs/2112.15422)[ic](https://www.youtube.com/watch?v=e7wFotDKEF4)[ally ](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html)[universal](https://www.wolframphysics.org/bulletins/), but practically, capabilities overlap but are [never exactly the same](https://www.google.com/search?q=is+fire+food). For an ML environment, this means that including all of another environment is an opportunity to get [more ](https://arxiv.org/abs/2005.14165)[data](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35179.pdf). (And the more data, the more general the learned solutions have to be, so it all works out.)

As long as we provide means to convert to & from at least a few other data environments, we form a network, effectively constructing a bigger 'universal standard'. This way, no one has to support everything, practicioners can just convert and AI models will learn.

Diversity of formats [could encourage meta-learning](https://arxiv.org/abs/2106.09017) unless it's too easy to learn, so it's all good.